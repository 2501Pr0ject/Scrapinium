# ğŸ—ï¸ Architecture Scrapinium

> Documentation technique de l'architecture logicielle

## ğŸ¯ Principes Architecturaux

### Philosophie
- **Modulaire** : Composants dÃ©couplÃ©s et rÃ©utilisables
- **Extensible** : Support facile de nouveaux LLMs et formats
- **Performant** : Traitement asynchrone et parallÃ¨le
- **SÃ©curisÃ©** : Gestion sÃ©curisÃ©e des clÃ©s et donnÃ©es
- **Observable** : Monitoring et logs complets

### Patterns
- **Hexagonal Architecture** : SÃ©paration mÃ©tier/infrastructure
- **Agent Pattern** : Agents autonomes LangGraph
- **Repository Pattern** : Abstraction de la persistance
- **Factory Pattern** : CrÃ©ation dynamique des LLMs
- **Observer Pattern** : Ã‰vÃ©nements et notifications

---

## ğŸ›ï¸ Vue d'ensemble

```mermaid
graph TB
    subgraph "Frontend Layer"
        UI[Reflex UI]
        WEB[Interface Web]
    end
    
    subgraph "API Layer"
        API[FastAPI REST API]
        WS[WebSocket Events]
        AUTH[Authentication]
    end
    
    subgraph "Business Layer"
        CORE[Core Logic]
        AGENTS[LangGraph Agents]
        WORKFLOW[Workflow Engine]
    end
    
    subgraph "Service Layer"
        SCRAPER[Scraping Service]
        LLM[LLM Service]
        STORAGE[Storage Service]
    end
    
    subgraph "Infrastructure Layer"
        DB[(Database)]
        REDIS[(Redis Cache)]
        OLLAMA[Ollama Server]
        QUEUE[Task Queue]
    end
    
    UI --> API
    WEB --> API
    API --> CORE
    CORE --> AGENTS
    AGENTS --> WORKFLOW
    WORKFLOW --> SCRAPER
    WORKFLOW --> LLM
    WORKFLOW --> STORAGE
    SCRAPER --> DB
    LLM --> OLLAMA
    STORAGE --> DB
    AGENTS --> REDIS
    WORKFLOW --> QUEUE
```

---

## ğŸ“¦ Structure des Modules

### `/src/scrapinium/`

```
scrapinium/
â”œâ”€â”€ core/              # ğŸ§  Logique mÃ©tier centrale
â”‚   â”œâ”€â”€ engine.py      # Moteur principal
â”‚   â”œâ”€â”€ workflow.py    # Orchestration des tÃ¢ches
â”‚   â””â”€â”€ events.py      # SystÃ¨me d'Ã©vÃ©nements
â”‚
â”œâ”€â”€ agents/            # ğŸ¤– Agents LangGraph
â”‚   â”œâ”€â”€ scraper.py     # Agent de scraping
â”‚   â”œâ”€â”€ extractor.py   # Agent d'extraction
â”‚   â”œâ”€â”€ formatter.py   # Agent de formatage
â”‚   â””â”€â”€ validator.py   # Agent de validation
â”‚
â”œâ”€â”€ scraping/          # ğŸ•·ï¸ Modules de scraping
â”‚   â”œâ”€â”€ browser.py     # Gestion navigateur
â”‚   â”œâ”€â”€ parser.py      # Parsing HTML/XML
â”‚   â”œâ”€â”€ extractor.py   # Extraction de contenu
â”‚   â””â”€â”€ filters.py     # Filtres et nettoyage
â”‚
â”œâ”€â”€ llm/               # ğŸ§  IntÃ©grations LLM
â”‚   â”œâ”€â”€ factory.py     # Factory des LLMs
â”‚   â”œâ”€â”€ ollama.py      # Client Ollama
â”‚   â”œâ”€â”€ openai.py      # Client OpenAI
â”‚   â”œâ”€â”€ anthropic.py   # Client Anthropic
â”‚   â””â”€â”€ mistral.py     # Client Mistral
â”‚
â”œâ”€â”€ api/               # ğŸŒ API REST
â”‚   â”œâ”€â”€ app.py         # Application FastAPI
â”‚   â”œâ”€â”€ routes/        # Endpoints API
â”‚   â”œâ”€â”€ middleware/    # Middlewares
â”‚   â””â”€â”€ schemas/       # SchÃ©mas Pydantic
â”‚
â”œâ”€â”€ ui/                # ğŸ¨ Interface utilisateur
â”‚   â”œâ”€â”€ app.py         # Application Reflex
â”‚   â”œâ”€â”€ pages/         # Pages interface
â”‚   â”œâ”€â”€ components/    # Composants rÃ©utilisables
â”‚   â””â”€â”€ styles/        # Styles CSS
â”‚
â”œâ”€â”€ models/            # ğŸ“Š ModÃ¨les de donnÃ©es
â”‚   â”œâ”€â”€ base.py        # ModÃ¨les de base
â”‚   â”œâ”€â”€ scraping.py    # ModÃ¨les scraping
â”‚   â”œâ”€â”€ llm.py         # ModÃ¨les LLM
â”‚   â””â”€â”€ user.py        # ModÃ¨les utilisateur
â”‚
â”œâ”€â”€ config/            # âš™ï¸ Configuration
â”‚   â”œâ”€â”€ settings.py    # ParamÃ¨tres application
â”‚   â”œâ”€â”€ database.py    # Configuration BDD
â”‚   â””â”€â”€ logging.py     # Configuration logs
â”‚
â””â”€â”€ utils/             # ğŸ› ï¸ Utilitaires
    â”œâ”€â”€ crypto.py      # Chiffrement
    â”œâ”€â”€ validators.py  # Validateurs
    â”œâ”€â”€ formatters.py  # Formatage donnÃ©es
    â””â”€â”€ helpers.py     # Fonctions utilitaires
```

---

## ğŸ”„ Flux de DonnÃ©es

### 1. Scraping Request Flow

```mermaid
sequenceDiagram
    participant U as User
    participant UI as Reflex UI
    participant API as FastAPI
    participant CORE as Core Engine
    participant AGENT as Scraper Agent
    participant SCRAPER as Scraping Service
    participant LLM as LLM Service
    participant DB as Database
    
    U->>UI: Submit URL + Format
    UI->>API: POST /scrape
    API->>CORE: Create scraping task
    CORE->>AGENT: Initialize agent workflow
    AGENT->>SCRAPER: Fetch webpage
    SCRAPER->>AGENT: Return raw content
    AGENT->>LLM: Structure content
    LLM->>AGENT: Return structured data
    AGENT->>DB: Save result
    AGENT->>CORE: Task completed
    CORE->>API: Return result
    API->>UI: JSON response
    UI->>U: Display structured data
```

### 2. Agent Workflow

```mermaid
graph LR
    START([Start]) --> PARSE[Parse URL]
    PARSE --> FETCH[Fetch Content]
    FETCH --> EXTRACT[Extract Main Content]
    EXTRACT --> CLASSIFY[Classify Content Type]
    CLASSIFY --> STRUCTURE[Structure with LLM]
    STRUCTURE --> FORMAT[Apply Output Format]
    FORMAT --> VALIDATE[Validate Result]
    VALIDATE --> SAVE[Save to Database]
    SAVE --> END([End])
    
    FETCH --> ERROR{Error?}
    STRUCTURE --> ERROR
    ERROR -->|Yes| RETRY[Retry Logic]
    ERROR -->|No| FORMAT
    RETRY --> FETCH
```

---

## ğŸ—ï¸ Couches Architecturales

### 1. PrÃ©sentation (UI/API)
- **ResponsabilitÃ©** : Interface utilisateur et endpoints API
- **Technologies** : Reflex, FastAPI, WebSocket
- **Patterns** : MVC, REST, Event-driven

### 2. Application (Core/Agents)
- **ResponsabilitÃ©** : Logique mÃ©tier et orchestration
- **Technologies** : LangGraph, Workflow Engine
- **Patterns** : Agent, Command, Observer

### 3. Domaine (Models/Services)
- **ResponsabilitÃ©** : ModÃ¨les mÃ©tier et services
- **Technologies** : Pydantic, SQLAlchemy
- **Patterns** : Repository, Factory, Strategy

### 4. Infrastructure (Database/External)
- **ResponsabilitÃ©** : Persistance et services externes
- **Technologies** : SQLite/PostgreSQL, Redis, Ollama
- **Patterns** : Adapter, Gateway, Circuit Breaker

---

## ğŸ¤– Architecture des Agents

### Agent Orchestration avec LangGraph

```python
from langgraph import StateGraph, END

def create_scraping_workflow():
    workflow = StateGraph()
    
    # Nodes
    workflow.add_node("fetch", fetch_content_node)
    workflow.add_node("extract", extract_content_node)
    workflow.add_node("structure", structure_with_llm_node)
    workflow.add_node("format", format_output_node)
    workflow.add_node("validate", validate_result_node)
    
    # Edges
    workflow.add_edge("fetch", "extract")
    workflow.add_edge("extract", "structure")
    workflow.add_edge("structure", "format")
    workflow.add_edge("format", "validate")
    workflow.add_edge("validate", END)
    
    # Conditional edges
    workflow.add_conditional_edges(
        "validate",
        should_retry,
        {"retry": "structure", "end": END}
    )
    
    return workflow.compile()
```

### Types d'Agents

1. **Scraper Agent** : Navigation et extraction
2. **Extractor Agent** : Analyse et structuration
3. **Formatter Agent** : Conversion de format
4. **Validator Agent** : VÃ©rification qualitÃ©
5. **Monitor Agent** : Surveillance performance

---

## ğŸ”’ SÃ©curitÃ©

### Chiffrement des ClÃ©s API
```python
from cryptography.fernet import Fernet

class APIKeyManager:
    def __init__(self, secret_key: str):
        self.cipher = Fernet(secret_key.encode())
    
    def encrypt_key(self, api_key: str) -> str:
        return self.cipher.encrypt(api_key.encode()).decode()
    
    def decrypt_key(self, encrypted_key: str) -> str:
        return self.cipher.decrypt(encrypted_key.encode()).decode()
```

### Validation et Sanitization
- Validation stricte des URLs
- Sanitization du contenu extrait
- Rate limiting par utilisateur
- Validation des formats de sortie

---

## ğŸ“Š Monitoring et ObservabilitÃ©

### MÃ©triques CollectÃ©es
- Temps de rÃ©ponse par endpoint
- Taux de succÃ¨s/Ã©chec du scraping
- Utilisation des LLMs (tokens, latence)
- Performance des agents
- Utilisation des ressources systÃ¨me

### Logging Structure
```json
{
  "timestamp": "2024-06-21T10:30:00Z",
  "level": "INFO",
  "service": "scraper_agent",
  "trace_id": "abc123",
  "user_id": "user456",
  "url": "https://example.com",
  "duration_ms": 1250,
  "status": "success",
  "llm_tokens": 324
}
```

---

## ğŸš€ DÃ©ploiement

### Conteneurisation
- **Application** : Container Python multi-stage
- **Services** : Redis, Ollama, PostgreSQL
- **Orchestration** : Docker Compose (dev), Kubernetes (prod)

### ScalabilitÃ©
- Load balancing avec Nginx
- Scaling horizontal des workers
- Cache distribuÃ© Redis
- Queue de tÃ¢ches Celery

---

## ğŸ”„ Ã‰volution Architecture

### Phase 1 (MVP)
- Architecture monolithique modulaire
- SQLite + Redis local
- Ollama local

### Phase 2 (Scale)
- Microservices sÃ©lectifs
- PostgreSQL + Redis cluster
- Multi-node Ollama

### Phase 3 (Enterprise)
- Architecture distribuÃ©e
- Multi-tenant
- Cloud-native deployment

---

<div align="center">
  <b>ğŸ—ï¸ Architecture Ã©volutive et maintenable</b><br>
  <i>ConÃ§ue pour grandir avec vos besoins</i>
</div>