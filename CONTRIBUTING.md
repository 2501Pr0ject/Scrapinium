# Guide de Contribution - Scrapinium

## ü§ù Bienvenue dans la Communaut√© Scrapinium !

Merci de votre int√©r√™t pour contribuer √† Scrapinium ! Ce guide vous aidera √† participer efficacement au d√©veloppement de ce projet open-source enterprise-grade.

## üéØ Types de Contributions

Nous accueillons tous types de contributions :

- üêõ **Bug Reports** : Signaler des probl√®mes
- ‚ú® **Features** : Proposer de nouvelles fonctionnalit√©s  
- üìö **Documentation** : Am√©liorer la documentation
- üß™ **Tests** : Ajouter ou am√©liorer les tests
- üîß **Performance** : Optimisations et am√©liorations
- üõ°Ô∏è **Security** : Corrections de s√©curit√©
- üåê **Traductions** : Internationalisation
- üí° **Id√©es** : Discussions et propositions

## üöÄ D√©marrage Rapide

### Pr√©requis

```bash
# Outils requis
- Python 3.9+
- Node.js 18+ (pour le frontend)
- Git
- Docker (optionnel)
- PostgreSQL ou SQLite

# Outils recommand√©s
- VS Code avec extensions Python
- Postman ou Insomnia (test API)
- Redis (pour le cache)
```

### Setup Environnement

```bash
# 1. Fork et clone le projet
git clone https://github.com/your-username/scrapinium.git
cd scrapinium

# 2. Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# 3. Installer les d√©pendances
pip install -r requirements.txt
pip install -r requirements-dev.txt

# 4. Installer Playwright
playwright install

# 5. Configuration environnement
cp .env.example .env
# √âditer .env avec vos param√®tres

# 6. Initialiser la base de donn√©es
python -m scrapinium.database init

# 7. Lancer les tests
python scripts/run_tests.py --level fast

# 8. D√©marrer le serveur
uvicorn src.scrapinium.api.app:app --reload
```

### Structure du Projet

```
scrapinium/
‚îú‚îÄ‚îÄ üìÅ src/scrapinium/          # Code source principal
‚îÇ   ‚îú‚îÄ‚îÄ api/                    # API FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ scraping/              # Moteur de scraping
‚îÇ   ‚îú‚îÄ‚îÄ llm/                   # Int√©gration LLM
‚îÇ   ‚îú‚îÄ‚îÄ cache/                 # Syst√®me de cache
‚îÇ   ‚îú‚îÄ‚îÄ security/              # S√©curit√© enterprise
‚îÇ   ‚îú‚îÄ‚îÄ utils/                 # Utilitaires
‚îÇ   ‚îî‚îÄ‚îÄ models/                # Mod√®les de donn√©es
‚îú‚îÄ‚îÄ üìÅ tests/                  # Tests complets
‚îú‚îÄ‚îÄ üìÅ docs/                   # Documentation
‚îú‚îÄ‚îÄ üìÅ templates/              # Templates web
‚îú‚îÄ‚îÄ üìÅ static/                 # Assets statiques
‚îú‚îÄ‚îÄ üìÅ scripts/                # Scripts utilitaires
‚îî‚îÄ‚îÄ üìÅ config/                 # Configurations
```

## üîÑ Workflow de Contribution

### 1. Cr√©er une Issue

**Avant de commencer, cr√©ez toujours une issue pour :**
- üêõ Rapporter un bug
- ‚ú® Proposer une nouvelle fonctionnalit√©
- üìö Am√©lioration de documentation
- üí¨ Discussion g√©n√©rale

**Template Bug Report :**
```markdown
## üêõ Bug Report

### Description
Description claire et concise du bug.

### Reproduction
√âtapes pour reproduire le comportement :
1. Aller √† '...'
2. Cliquer sur '...'
3. Voir l'erreur

### Comportement Attendu
Description de ce qui devrait se passer.

### Captures d'√âcran
Si applicable, ajoutez des captures d'√©cran.

### Environnement
- OS: [ex. macOS 12.0]
- Python: [ex. 3.9.7]
- Version: [ex. 2.0.0]

### Logs
```
Coller les logs d'erreur ici
```

### Contexte Additionnel
Autres informations utiles.
```

**Template Feature Request :**
```markdown
## ‚ú® Feature Request

### Problem
Description claire du probl√®me que cette feature r√©soudrait.

### Solution Propos√©e
Description claire de ce que vous voulez qu'il se passe.

### Alternatives Consid√©r√©es
Autres solutions ou fonctionnalit√©s que vous avez consid√©r√©es.

### Impact
- Performance: [impact pr√©vu]
- Compatibilit√©: [breaking changes?]
- Complexit√©: [1-5, 5 = tr√®s complexe]

### Impl√©mentation
Id√©es d'impl√©mentation si vous en avez.
```

### 2. D√©veloppement

**Branch Naming Convention :**
```bash
# Features
feature/add-websocket-support
feature/improve-cache-performance

# Bug fixes
bugfix/fix-memory-leak-browser-pool
bugfix/correct-rate-limiting-headers

# Documentation
docs/update-api-reference
docs/add-deployment-guide

# Security
security/fix-xss-vulnerability
security/improve-input-validation
```

**Cr√©ation de Branch :**
```bash
# Synchroniser avec main
git checkout main
git pull upstream main

# Cr√©er nouvelle branch
git checkout -b feature/your-feature-name

# D√©velopper et commiter
git add .
git commit -m "feat: add your feature description"

# Pousser la branch
git push origin feature/your-feature-name
```

### 3. Standards de Code

#### Python Code Style

**Nous utilisons :**
- ‚úÖ **Black** pour le formatage automatique
- ‚úÖ **isort** pour l'organisation des imports
- ‚úÖ **flake8** pour le linting
- ‚úÖ **mypy** pour le type checking
- ‚úÖ **pytest** pour les tests

**Configuration pr√©-commit :**
```bash
# Installer pre-commit
pip install pre-commit
pre-commit install

# Lancer manuellement
pre-commit run --all-files
```

**Style Guidelines :**
```python
# ‚úÖ Bon exemple
from typing import Dict, List, Optional, AsyncIterator
import asyncio
import logging

from fastapi import HTTPException, Request
from pydantic import BaseModel, validator

from ..config import settings
from ..utils.security import validate_url

logger = logging.getLogger(__name__)


class ScrapingRequest(BaseModel):
    """Mod√®le de requ√™te de scraping avec validation."""
    
    url: str
    use_llm: bool = False
    custom_instructions: Optional[str] = None
    
    @validator("url")
    def validate_url_format(cls, v: str) -> str:
        """Validation de l'URL avec s√©curit√©."""
        if not v.startswith(("http://", "https://")):
            raise ValueError("URL doit commencer par http:// ou https://")
        
        # Validation s√©curis√©e
        validated_url = validate_url(v)
        if not validated_url.is_valid:
            raise ValueError(f"URL invalide: {validated_url.errors}")
        
        return validated_url.sanitized_value


async def process_scraping_request(
    request: ScrapingRequest,
    user_id: Optional[str] = None
) -> Dict[str, any]:
    """
    Traiter une requ√™te de scraping.
    
    Args:
        request: Donn√©es de la requ√™te valid√©es
        user_id: ID utilisateur optionnel
        
    Returns:
        R√©sultat du scraping avec m√©tadonn√©es
        
    Raises:
        HTTPException: Si erreur de traitement
    """
    try:
        logger.info(f"Traitement scraping pour {request.url}")
        
        # Traitement async
        result = await scraping_service.process_url(
            url=request.url,
            use_llm=request.use_llm,
            instructions=request.custom_instructions,
            user_id=user_id
        )
        
        return {
            "success": True,
            "data": result,
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Erreur scraping {request.url}: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur de traitement: {str(e)}"
        )
```

#### Frontend Code Style

**JavaScript/HTML Standards :**
```javascript
// ‚úÖ Bon exemple - JavaScript moderne
class ScrapingDashboard {
    constructor(apiClient) {
        this.apiClient = apiClient;
        this.charts = new Map();
        this.updateInterval = null;
    }
    
    async initialize() {
        try {
            await this.loadInitialData();
            this.setupEventListeners();
            this.startAutoRefresh();
            
            console.log('Dashboard initialis√© avec succ√®s');
        } catch (error) {
            console.error('Erreur initialisation dashboard:', error);
            this.showErrorMessage('Impossible de charger le dashboard');
        }
    }
    
    async loadInitialData() {
        const [stats, tasks] = await Promise.all([
            this.apiClient.getStats(),
            this.apiClient.getTasks({ limit: 10 })
        ]);
        
        this.updateStatsDisplay(stats);
        this.updateTasksList(tasks);
    }
    
    setupEventListeners() {
        // Event delegation pour performance
        document.addEventListener('click', (event) => {
            if (event.target.matches('.scrape-btn')) {
                this.handleScrapeRequest(event);
            }
        });
        
        // Cleanup on page unload
        window.addEventListener('beforeunload', () => {
            this.cleanup();
        });
    }
    
    cleanup() {
        if (this.updateInterval) {
            clearInterval(this.updateInterval);
        }
    }
}
```

### 4. Tests

**Types de Tests :**
```bash
# Tests unitaires rapides
python scripts/run_tests.py --level unit

# Tests d'int√©gration
python scripts/run_tests.py --level integration

# Tests de s√©curit√©
python scripts/run_tests.py --markers security

# Tests complets
python scripts/run_tests.py --level all --coverage
```

**√âcriture de Tests :**
```python
# tests/test_your_feature.py

import pytest
from fastapi.testclient import TestClient
from unittest.mock import Mock, patch

from src.scrapinium.api.app import create_app


class TestYourFeature:
    """Tests pour votre nouvelle fonctionnalit√©."""
    
    @pytest.fixture
    def client(self):
        """Client de test FastAPI."""
        app = create_app()
        return TestClient(app)
    
    @pytest.fixture
    def mock_data(self):
        """Donn√©es de test."""
        return {
            "url": "https://example.com",
            "expected_result": "content processed"
        }
    
    def test_basic_functionality(self, client, mock_data):
        """Test de base de la fonctionnalit√©."""
        response = client.post("/your-endpoint", json=mock_data)
        
        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True
        assert "result" in data["data"]
    
    @pytest.mark.parametrize("invalid_input,expected_error", [
        ("", "URL requise"),
        ("invalid-url", "Format URL invalide"),
        ("javascript:alert('xss')", "URL non autoris√©e")
    ])
    def test_input_validation(self, client, invalid_input, expected_error):
        """Test de validation des inputs."""
        response = client.post("/your-endpoint", json={"url": invalid_input})
        
        assert response.status_code == 422
        error_data = response.json()
        assert expected_error in str(error_data)
    
    @patch('src.scrapinium.scraping.service.scrape_url')
    async def test_error_handling(self, mock_scrape, client):
        """Test de gestion d'erreurs."""
        # Simuler une erreur
        mock_scrape.side_effect = Exception("Network error")
        
        response = client.post("/your-endpoint", json={
            "url": "https://example.com"
        })
        
        assert response.status_code == 500
        error_data = response.json()
        assert "Network error" in error_data["detail"]
```

### 5. Documentation

**Docstrings Standards :**
```python
def complex_function(
    param1: str,
    param2: Optional[int] = None,
    **kwargs
) -> Dict[str, Any]:
    """
    Description courte de la fonction.
    
    Description d√©taill√©e si n√©cessaire, avec explications
    sur l'algorithme, les cas d'usage, etc.
    
    Args:
        param1: Description du premier param√®tre
        param2: Description du second param√®tre (optionnel)
        **kwargs: Param√®tres additionnels
            - special_option: Description de l'option
            - another_option: Autre option possible
    
    Returns:
        Dictionnaire contenant:
            - result: R√©sultat principal
            - metadata: M√©tadonn√©es du traitement
            - success: Bool√©en de succ√®s
    
    Raises:
        ValueError: Si param1 est vide
        HTTPException: Si erreur r√©seau
        
    Example:
        >>> result = complex_function("test", param2=42)
        >>> print(result["success"])
        True
        
    Note:
        Cette fonction est optimis√©e pour de gros volumes.
        Utiliser avec pr√©caution en production.
    """
```

**Documentation API :**
```python
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

router = APIRouter(prefix="/api/v1", tags=["scraping"])


class ScrapeRequest(BaseModel):
    """
    Mod√®le de requ√™te de scraping.
    
    Attributes:
        url: URL √† scraper (HTTPS recommand√©)
        use_llm: Utiliser LLM pour traitement
        instructions: Instructions personnalis√©es
    """
    url: str
    use_llm: bool = False
    instructions: Optional[str] = None


@router.post(
    "/scrape",
    summary="Cr√©er une t√¢che de scraping",
    description="""
    Cr√©e une nouvelle t√¢che de scraping pour l'URL sp√©cifi√©e.
    
    - **url**: URL √† scraper (doit √™tre accessible publiquement)
    - **use_llm**: Active le traitement par LLM pour structurer le contenu
    - **instructions**: Instructions personnalis√©es pour le LLM
    
    La t√¢che est trait√©e de mani√®re asynchrone. Utilisez l'endpoint
    `/scrape/{task_id}` pour suivre le progr√®s.
    """,
    response_description="T√¢che cr√©√©e avec succ√®s",
    responses={
        200: {
            "description": "T√¢che cr√©√©e",
            "content": {
                "application/json": {
                    "example": {
                        "success": True,
                        "data": {
                            "task_id": "task_123456789",
                            "status": "pending"
                        }
                    }
                }
            }
        },
        422: {"description": "Param√®tres invalides"},
        429: {"description": "Rate limit d√©pass√©"}
    }
)
async def create_scraping_task(request: ScrapeRequest):
    """Cr√©er une nouvelle t√¢che de scraping."""
    # Impl√©mentation...
```

## üìã Pull Request Process

### 1. Checklist Pr√©-PR

**Avant de soumettre :**
- [ ] Tests ajout√©s/mis √† jour
- [ ] Documentation mise √† jour
- [ ] Code format√© (black, isort)
- [ ] Linting pass√© (flake8, mypy)
- [ ] Tests passent localement
- [ ] Commits sign√©s (optionnel mais recommand√©)

### 2. Template Pull Request

```markdown
## üìù Description

R√©sum√© clair des changements et des raisons.

Fixes #(issue_number)

## üîÑ Type de Changement

- [ ] üêõ Bug fix (changement non-breaking qui corrige un probl√®me)
- [ ] ‚ú® New feature (changement non-breaking qui ajoute une fonctionnalit√©)
- [ ] üí• Breaking change (fix ou feature qui casserait les fonctionnalit√©s existantes)
- [ ] üìö Documentation update

## üß™ Comment Tester

Instructions d√©taill√©es pour tester vos changements :

1. √âtape 1
2. √âtape 2
3. R√©sultat attendu

## üìã Checklist

- [ ] Mon code suit les guidelines du projet
- [ ] J'ai effectu√© une auto-review de mon code
- [ ] J'ai comment√© mon code, particuli√®rement les parties complexes
- [ ] J'ai fait les changements de documentation correspondants
- [ ] Mes changements ne g√©n√®rent pas de nouveaux warnings
- [ ] J'ai ajout√© des tests qui prouvent que mon fix est efficace ou que ma feature fonctionne
- [ ] Les tests unitaires nouveaux et existants passent localement
- [ ] Toutes les d√©pendances sont √† jour

## üìä Impact Performance

Si applicable, d√©taillez l'impact sur les performances :
- Temps d'ex√©cution : +/- X%
- Utilisation m√©moire : +/- X MB
- Benchmarks avant/apr√®s

## üîí S√©curit√©

Si ce changement a des implications de s√©curit√© :
- [ ] Audit de s√©curit√© effectu√©
- [ ] Tests de s√©curit√© ajout√©s
- [ ] Documentation s√©curit√© mise √† jour

## üì∏ Screenshots

Si applicable, ajoutez des screenshots des changements UI.

## üîó R√©f√©rences

- Issue connexe: #XXX
- Documentation: [lien]
- Discussions: [lien]
```

### 3. Review Process

**Nos crit√®res de review :**

1. **Fonctionnalit√©** 
   - ‚úÖ Code fonctionne comme attendu
   - ‚úÖ Cas limites g√©r√©s
   - ‚úÖ Erreurs g√©r√©es proprement

2. **Qualit√© Code**
   - ‚úÖ Code lisible et maintenable
   - ‚úÖ Standards de codage respect√©s
   - ‚úÖ Architecture coh√©rente

3. **Tests**
   - ‚úÖ Couverture de test ad√©quate
   - ‚úÖ Tests edge cases
   - ‚úÖ Tests de r√©gression

4. **S√©curit√©**
   - ‚úÖ Pas de vuln√©rabilit√©s introduites
   - ‚úÖ Validation des inputs
   - ‚úÖ Gestion des erreurs s√©curis√©e

5. **Performance**
   - ‚úÖ Pas de r√©gression performance
   - ‚úÖ Optimisations appropri√©es
   - ‚úÖ Utilisation m√©moire raisonnable

6. **Documentation**
   - ‚úÖ Documentation √† jour
   - ‚úÖ Comments appropri√©s
   - ‚úÖ API documentation mise √† jour

## üéñÔ∏è Reconnaissance

### Hall of Fame

Nous reconnaissons nos contributeurs de plusieurs fa√ßons :

- üèÜ **Contributors Wall** dans le README
- üéØ **Badges sp√©cialis√©s** (Security, Performance, Documentation, etc.)
- üìß **Newsletter mentions** pour contributions majeures
- üéÅ **Goodies** pour contributeurs r√©guliers

### Types de Contributeurs

- ü•á **Core Maintainer** : Acc√®s write, d√©cisions techniques
- ü•à **Regular Contributor** : 10+ PRs accept√©es
- ü•â **Active Contributor** : 5+ PRs accept√©es  
- üåü **Community Helper** : Support utilisateurs, documentation
- üêõ **Bug Hunter** : 5+ bugs report√©s/corrig√©s
- üõ°Ô∏è **Security Researcher** : Vuln√©rabilit√©s d√©couvertes
- üìö **Documentation Expert** : Am√©liorations documentation

## ü§î Besoin d'Aide ?

### Ressources

- üìñ **Documentation** : `/docs` folder
- üí¨ **Discussions** : GitHub Discussions
- üêõ **Issues** : GitHub Issues
- üìß **Email** : contributors@scrapinium.com

### Mentorship

Nouveau contributeur ? Nous avons un programme de mentorship !

- ‚úÖ Issues √©tiquet√©es `good-first-issue`
- ‚úÖ Issues √©tiquet√©es `help-wanted`
- ‚úÖ Mentoring par des contributeurs exp√©riment√©s
- ‚úÖ Sessions de code review en live (monthly)

### Communication

- **GitHub Discussions** : Questions g√©n√©rales, id√©es
- **GitHub Issues** : Bugs, feature requests
- **Email** : Probl√®mes priv√©s, s√©curit√©
- **Discord** : Chat informel (lien dans README)

## üìÑ Licence

En contribuant √† Scrapinium, vous acceptez que vos contributions soient licenci√©es sous la m√™me licence que le projet.

---

**Merci de contribuer √† Scrapinium ! üöÄ**

Ensemble, construisons le meilleur outil de scraping open-source du march√© !

---

**Version**: 1.0.0  
**Derni√®re mise √† jour**: 2024-12-21  
**Maintainers**: @core-team