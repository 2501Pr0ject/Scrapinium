#!/usr/bin/env python3
"""
Moniteur de performance en temps r√©el pour Scrapinium.
Surveille et alerte sur les performances du syst√®me.
"""

import asyncio
import time
import json
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
import argparse
from pathlib import Path

import aiohttp
import psutil


class PerformanceMonitor:
    """Moniteur de performance en temps r√©el."""
    
    def __init__(
        self, 
        base_url: str = "http://localhost:8000",
        alert_thresholds: Dict[str, float] = None
    ):
        self.base_url = base_url.rstrip('/')
        self.session = None
        self.running = False
        self.metrics_history: List[Dict[str, Any]] = []
        
        # Seuils d'alerte par d√©faut
        self.alert_thresholds = alert_thresholds or {
            "response_time_ms": 5000,     # Temps de r√©ponse > 5s
            "memory_usage_mb": 1024,       # M√©moire > 1GB
            "cpu_usage_percent": 80,       # CPU > 80%
            "cache_hit_rate": 0.7,         # Cache hit rate < 70%
            "error_rate_percent": 10,      # Taux d'erreur > 10%
            "queue_length": 10             # File d'attente > 10
        }
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def collect_metrics(self) -> Dict[str, Any]:
        """Collecte les m√©triques du syst√®me."""
        
        timestamp = datetime.now()
        metrics = {
            "timestamp": timestamp.isoformat(),
            "system": {},
            "api": {},
            "scrapinium": {}
        }
        
        try:
            # M√©triques syst√®me
            process = psutil.Process()
            metrics["system"] = {
                "cpu_percent": process.cpu_percent(),
                "memory_mb": process.memory_info().rss / 1024 / 1024,
                "memory_percent": process.memory_percent(),
                "threads": process.num_threads(),
                "connections": len(process.connections()),
                "uptime_seconds": time.time() - process.create_time()
            }
            
            # M√©triques API de base
            try:
                async with self.session.get(f"{self.base_url}/health", timeout=5) as response:
                    if response.status == 200:
                        metrics["api"]["health"] = "ok"
                        metrics["api"]["response_time_ms"] = response.headers.get("x-response-time", 0)
                    else:
                        metrics["api"]["health"] = f"error_{response.status}"
            except asyncio.TimeoutError:
                metrics["api"]["health"] = "timeout"
            except Exception as e:
                metrics["api"]["health"] = f"error_{str(e)}"
            
            # M√©triques Scrapinium sp√©cifiques
            await self._collect_scrapinium_metrics(metrics)
            
        except Exception as e:
            print(f"‚ùå Erreur collecte m√©triques: {e}")
            metrics["error"] = str(e)
        
        return metrics
    
    async def _collect_scrapinium_metrics(self, metrics: Dict[str, Any]):
        """Collecte les m√©triques sp√©cifiques √† Scrapinium."""
        
        scrapinium_metrics = {}
        
        # Statistiques g√©n√©rales
        try:
            async with self.session.get(f"{self.base_url}/stats", timeout=5) as response:
                if response.status == 200:
                    stats = await response.json()
                    scrapinium_metrics["general"] = stats.get("data", {})
        except Exception as e:
            scrapinium_metrics["general_error"] = str(e)
        
        # M√©triques de performance
        try:
            async with self.session.get(f"{self.base_url}/performance/metrics/live", timeout=5) as response:
                if response.status == 200:
                    perf_data = await response.json()
                    scrapinium_metrics["performance"] = perf_data.get("data", {})
        except Exception as e:
            scrapinium_metrics["performance_error"] = str(e)
        
        # M√©triques du cache
        try:
            async with self.session.get(f"{self.base_url}/stats/cache", timeout=5) as response:
                if response.status == 200:
                    cache_data = await response.json()
                    scrapinium_metrics["cache"] = cache_data.get("data", {})
        except Exception as e:
            scrapinium_metrics["cache_error"] = str(e)
        
        # M√©triques m√©moire
        try:
            async with self.session.get(f"{self.base_url}/stats/memory", timeout=5) as response:
                if response.status == 200:
                    memory_data = await response.json()
                    scrapinium_metrics["memory"] = memory_data.get("data", {})
        except Exception as e:
            scrapinium_metrics["memory_error"] = str(e)
        
        # M√©triques du pool de navigateurs
        try:
            async with self.session.get(f"{self.base_url}/stats/browser", timeout=5) as response:
                if response.status == 200:
                    browser_data = await response.json()
                    scrapinium_metrics["browser_pool"] = browser_data.get("data", {})
        except Exception as e:
            scrapinium_metrics["browser_error"] = str(e)
        
        metrics["scrapinium"] = scrapinium_metrics
    
    def check_alerts(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """V√©rifie les seuils d'alerte et retourne les alertes actives."""
        
        alerts = []
        
        # Alerte temps de r√©ponse
        response_time = metrics.get("api", {}).get("response_time_ms", 0)
        if isinstance(response_time, (int, float)) and response_time > self.alert_thresholds["response_time_ms"]:
            alerts.append({
                "type": "response_time",
                "severity": "warning",
                "message": f"Temps de r√©ponse √©lev√©: {response_time}ms",
                "threshold": self.alert_thresholds["response_time_ms"],
                "current_value": response_time
            })
        
        # Alerte m√©moire
        memory_mb = metrics.get("system", {}).get("memory_mb", 0)
        if memory_mb > self.alert_thresholds["memory_usage_mb"]:
            alerts.append({
                "type": "memory_usage",
                "severity": "warning" if memory_mb < self.alert_thresholds["memory_usage_mb"] * 1.5 else "critical",
                "message": f"Consommation m√©moire √©lev√©e: {memory_mb:.0f}MB",
                "threshold": self.alert_thresholds["memory_usage_mb"],
                "current_value": memory_mb
            })
        
        # Alerte CPU
        cpu_percent = metrics.get("system", {}).get("cpu_percent", 0)
        if cpu_percent > self.alert_thresholds["cpu_usage_percent"]:
            alerts.append({
                "type": "cpu_usage",
                "severity": "warning",
                "message": f"Utilisation CPU √©lev√©e: {cpu_percent:.1f}%",
                "threshold": self.alert_thresholds["cpu_usage_percent"],
                "current_value": cpu_percent
            })
        
        # Alerte cache hit rate
        cache_stats = metrics.get("scrapinium", {}).get("cache", {})
        if cache_stats and "hit_rate" in cache_stats:
            hit_rate = cache_stats["hit_rate"]
            if hit_rate < self.alert_thresholds["cache_hit_rate"]:
                alerts.append({
                    "type": "cache_hit_rate",
                    "severity": "info",
                    "message": f"Taux de hit cache faible: {hit_rate:.1%}",
                    "threshold": self.alert_thresholds["cache_hit_rate"],
                    "current_value": hit_rate
                })
        
        # Alerte taux d'erreur
        general_stats = metrics.get("scrapinium", {}).get("general", {})
        if general_stats and "failed_tasks" in general_stats and "total_tasks" in general_stats:
            total = general_stats["total_tasks"]
            failed = general_stats["failed_tasks"]
            if total > 0:
                error_rate = (failed / total) * 100
                if error_rate > self.alert_thresholds["error_rate_percent"]:
                    alerts.append({
                        "type": "error_rate",
                        "severity": "warning",
                        "message": f"Taux d'erreur √©lev√©: {error_rate:.1f}%",
                        "threshold": self.alert_thresholds["error_rate_percent"],
                        "current_value": error_rate
                    })
        
        # Alerte file d'attente
        browser_pool = metrics.get("scrapinium", {}).get("browser_pool", {})
        if browser_pool and "queue_length" in browser_pool:
            queue_length = browser_pool["queue_length"]
            if queue_length > self.alert_thresholds["queue_length"]:
                alerts.append({
                    "type": "queue_length",
                    "severity": "warning",
                    "message": f"File d'attente longue: {queue_length} t√¢ches",
                    "threshold": self.alert_thresholds["queue_length"],
                    "current_value": queue_length
                })
        
        return alerts
    
    def print_dashboard(self, metrics: Dict[str, Any], alerts: List[Dict[str, Any]]):
        """Affiche un dashboard en temps r√©el."""
        
        # Effacer l'√©cran
        print("\033[2J\033[H", end="")
        
        # En-t√™te
        print("=" * 80)
        print(f"üìä SCRAPINIUM PERFORMANCE DASHBOARD - {metrics['timestamp']}")
        print("=" * 80)
        
        # Statut g√©n√©ral
        api_health = metrics.get("api", {}).get("health", "unknown")
        health_icon = "‚úÖ" if api_health == "ok" else "‚ùå"
        print(f"\nüîç STATUT G√âN√âRAL: {health_icon} API {api_health.upper()}")
        
        # M√©triques syst√®me
        system = metrics.get("system", {})
        print(f"\nüñ•Ô∏è  SYST√àME:")
        print(f"   CPU: {system.get('cpu_percent', 0):.1f}%")
        print(f"   M√©moire: {system.get('memory_mb', 0):.0f} MB ({system.get('memory_percent', 0):.1f}%)")
        print(f"   Threads: {system.get('threads', 0)}")
        print(f"   Connexions: {system.get('connections', 0)}")
        
        # M√©triques Scrapinium
        scrap = metrics.get("scrapinium", {})
        
        # Statistiques g√©n√©rales
        general = scrap.get("general", {})
        if general:
            print(f"\nüìà T√ÇCHES:")
            print(f"   Total: {general.get('total_tasks', 0)}")
            print(f"   Actives: {general.get('active_tasks', 0)}")
            print(f"   Termin√©es: {general.get('completed_tasks', 0)}")
            print(f"   √âchou√©es: {general.get('failed_tasks', 0)}")
            print(f"   Taux de succ√®s: {general.get('success_rate', 0):.1f}%")
        
        # Cache
        cache = scrap.get("cache", {})
        if cache:
            print(f"\nüíæ CACHE:")
            print(f"   Hit rate: {cache.get('hit_rate', 0):.1%}")
            print(f"   Entr√©es: {cache.get('total_entries', 0)}")
            print(f"   M√©moire: {cache.get('memory_usage_mb', 0):.0f} MB")
        
        # Pool de navigateurs
        browser = scrap.get("browser_pool", {})
        if browser:
            print(f"\nüåê NAVIGATEURS:")
            print(f"   Actifs: {browser.get('active_browsers', 0)}")
            print(f"   Disponibles: {browser.get('available_browsers', 0)}")
            print(f"   File d'attente: {browser.get('queue_length', 0)}")
        
        # Performance
        perf = scrap.get("performance", {})
        if perf:
            current_metrics = perf.get("current_metrics", {})
            summary = perf.get("performance_summary", {})
            
            print(f"\n‚ö° PERFORMANCE:")
            print(f"   Op√©rations totales: {summary.get('total_operations', 0)}")
            print(f"   Dur√©e moyenne: {summary.get('average_duration_ms', 0):.0f} ms")
            print(f"   P95: {summary.get('p95_duration_ms', 0):.0f} ms")
            print(f"   Goulots d'√©tranglement: {summary.get('active_bottlenecks', 0)}")
        
        # Alertes
        if alerts:
            print(f"\nüö® ALERTES ({len(alerts)}):")
            for alert in alerts:
                severity_icon = {
                    "info": "‚ÑπÔ∏è",
                    "warning": "‚ö†Ô∏è", 
                    "critical": "üî•"
                }.get(alert["severity"], "‚ùì")
                print(f"   {severity_icon} {alert['message']}")
        else:
            print(f"\n‚úÖ Aucune alerte active")
        
        # Pied de page
        print("\n" + "=" * 80)
        print("Appuyez sur Ctrl+C pour arr√™ter")
    
    def save_metrics_history(self, filepath: str):
        """Sauvegarde l'historique des m√©triques."""
        
        try:
            with open(filepath, 'w') as f:
                json.dump(self.metrics_history, f, indent=2)
            print(f"üíæ Historique sauvegard√©: {filepath}")
        except Exception as e:
            print(f"‚ùå Erreur sauvegarde: {e}")
    
    def analyze_trends(self) -> Dict[str, Any]:
        """Analyse les tendances des m√©triques."""
        
        if len(self.metrics_history) < 2:
            return {"error": "Pas assez de donn√©es pour l'analyse"}
        
        recent = self.metrics_history[-10:]  # 10 derni√®res mesures
        
        analysis = {
            "memory_trend": self._calculate_trend([m.get("system", {}).get("memory_mb", 0) for m in recent]),
            "cpu_trend": self._calculate_trend([m.get("system", {}).get("cpu_percent", 0) for m in recent]),
            "response_time_trend": self._calculate_trend([
                m.get("api", {}).get("response_time_ms", 0) for m in recent
            ]),
            "total_measurements": len(self.metrics_history),
            "time_span_minutes": (datetime.fromisoformat(recent[-1]["timestamp"]) - 
                                datetime.fromisoformat(recent[0]["timestamp"])).total_seconds() / 60
        }
        
        return analysis
    
    def _calculate_trend(self, values: List[float]) -> str:
        """Calcule la tendance d'une s√©rie de valeurs."""
        
        if len(values) < 2:
            return "stable"
        
        # Calcul de la pente
        n = len(values)
        x = list(range(n))
        x_mean = sum(x) / n
        y_mean = sum(values) / n
        
        numerator = sum((x[i] - x_mean) * (values[i] - y_mean) for i in range(n))
        denominator = sum((x[i] - x_mean) ** 2 for i in range(n))
        
        if denominator == 0:
            return "stable"
        
        slope = numerator / denominator
        
        # Classification de la tendance
        if abs(slope) < 0.1:
            return "stable"
        elif slope > 0:
            return "increasing"
        else:
            return "decreasing"
    
    async def run_monitoring(
        self, 
        interval_seconds: int = 30,
        save_interval_minutes: int = 10,
        output_file: str = None
    ):
        """Lance le monitoring en temps r√©el."""
        
        self.running = True
        last_save = time.time()
        
        print(f"üöÄ D√©marrage du monitoring (intervalle: {interval_seconds}s)")
        
        try:
            while self.running:
                # Collecte des m√©triques
                metrics = await self.collect_metrics()
                self.metrics_history.append(metrics)
                
                # V√©rification des alertes
                alerts = self.check_alerts(metrics)
                
                # Affichage du dashboard
                self.print_dashboard(metrics, alerts)
                
                # Sauvegarde p√©riodique
                if output_file and (time.time() - last_save) > (save_interval_minutes * 60):
                    self.save_metrics_history(output_file)
                    last_save = time.time()
                
                # Limiter l'historique en m√©moire
                if len(self.metrics_history) > 1000:
                    self.metrics_history = self.metrics_history[-500:]  # Garder les 500 derni√®res
                
                await asyncio.sleep(interval_seconds)
                
        except KeyboardInterrupt:
            print("\n\nüõë Arr√™t du monitoring...")
            self.running = False
            
            if output_file:
                self.save_metrics_history(output_file)
            
            # Analyse finale
            analysis = self.analyze_trends()
            if "error" not in analysis:
                print("\nüìä ANALYSE DES TENDANCES:")
                print(f"   M√©moire: {analysis['memory_trend']}")
                print(f"   CPU: {analysis['cpu_trend']}")
                print(f"   Temps de r√©ponse: {analysis['response_time_trend']}")
                print(f"   Dur√©e de monitoring: {analysis['time_span_minutes']:.1f} minutes")


def main():
    """Point d'entr√©e principal."""
    
    parser = argparse.ArgumentParser(description="Moniteur de performance Scrapinium")
    parser.add_argument("--url", default="http://localhost:8000", help="URL de base de l'API")
    parser.add_argument("--interval", type=int, default=30, help="Intervalle de collecte (secondes)")
    parser.add_argument("--output", help="Fichier de sortie pour l'historique")
    parser.add_argument("--save-interval", type=int, default=10, help="Intervalle de sauvegarde (minutes)")
    
    # Seuils d'alerte personnalis√©s
    parser.add_argument("--memory-threshold", type=float, default=1024, help="Seuil m√©moire (MB)")
    parser.add_argument("--cpu-threshold", type=float, default=80, help="Seuil CPU (%)")
    parser.add_argument("--response-threshold", type=float, default=5000, help="Seuil temps r√©ponse (ms)")
    
    args = parser.parse_args()
    
    # Configuration des seuils
    thresholds = {
        "memory_usage_mb": args.memory_threshold,
        "cpu_usage_percent": args.cpu_threshold,
        "response_time_ms": args.response_threshold,
        "cache_hit_rate": 0.7,
        "error_rate_percent": 10,
        "queue_length": 10
    }
    
    async def run():
        async with PerformanceMonitor(args.url, thresholds) as monitor:
            await monitor.run_monitoring(
                interval_seconds=args.interval,
                save_interval_minutes=args.save_interval,
                output_file=args.output
            )
    
    try:
        asyncio.run(run())
    except KeyboardInterrupt:
        print("\nüëã Au revoir!")
        return 0
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return 1


if __name__ == "__main__":
    exit(main())